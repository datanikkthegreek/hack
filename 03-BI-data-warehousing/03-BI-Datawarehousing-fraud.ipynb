{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5ddbea1-702e-49f7-bf9a-f755493934ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Your Lakehouse is the best Warehouse\n",
    "\n",
    "Traditional Data Warehouses can’t keep up with the variety of data and use cases. Business agility requires reliable, real-time data, with insight from ML models.\n",
    "\n",
    "Working with the lakehouse unlock traditional BI analysis but also real time applications having a direct connection to your entire data, while remaining fully secured.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/images/dbsql.png\" width=\"700px\" style=\"float: left\" />\n",
    "\n",
    "<div style=\"float: left; margin-top: 240px; font-size: 23px\">\n",
    "  Instant, elastic compute<br>\n",
    "  Lower TCO with Serveless<br>\n",
    "  Zero management<br><br>\n",
    "\n",
    "  Governance layer - row level<br><br>\n",
    "\n",
    "  Your data. Your schema (star, data vault…)\n",
    "</div>\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=984752964297111&notebook=%2F03-BI-data-warehousing%2F03-BI-Datawarehousing-fraud&demo_name=lakehouse-fsi-fraud&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-fraud%2F03-BI-data-warehousing%2F03-BI-Datawarehousing-fraud&version=1&user_hash=086247655aad7f847fc5af0bced92d31b6454844129a39a1b73eef221886867a\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "373e5f68-d887-487e-8a63-2ede43b23b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# BI & Datawarehousing with Databricks SQL\n",
    "\n",
    "<img style=\"float: right; margin-top: 10px\" width=\"500px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/lakehouse-fsi-fraud-overview-3.png\" />\n",
    "\n",
    "Our datasets are now properly ingested, secured, with a high quality and easily discoverable within our organization.\n",
    "\n",
    "Let's explore how Databricks SQL support your Data Analyst team with interactive BI and start analyzing our transactions and Fraud.\n",
    "\n",
    "To start with Databricks SQL, open the SQL view on the top left menu.\n",
    "\n",
    "You'll be able to:\n",
    "\n",
    "- Create a SQL Warehouse to run your queries\n",
    "- Use DBSQL to build your own dashboards\n",
    "- Plug any BI tools (Tableau/PowerBI/..) to run your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bd893f4-3e5b-4b47-bce4-cb31124cc126",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Databricks SQL Warehouses: best-in-class BI engine\n",
    "\n",
    "<img style=\"float: right; margin-left: 10px\" width=\"600px\" src=\"https://www.databricks.com/wp-content/uploads/2022/06/how-does-it-work-image-5.svg\" />\n",
    "\n",
    "Databricks SQL is a warehouse engine packed with thousands of optimizations to provide you with the best performance for all your tools, query types and real-world applications. <a href='https://www.databricks.com/blog/2021/11/02/databricks-sets-official-data-warehousing-performance-record.html'>It won the Data Warehousing Performance Record.</a>\n",
    "\n",
    "This includes the next-generation vectorized query engine Photon, which together with SQL warehouses, provides up to 12x better price/performance than other cloud data warehouses.\n",
    "\n",
    "**Serverless warehouse** provide instant, elastic SQL compute — decoupled from storage — and will automatically scale to provide unlimited concurrency without disruption, for high concurrency use cases.\n",
    "\n",
    "Make no compromise. Your best Datawarehouse is a Lakehouse.\n",
    "\n",
    "### Creating a SQL Warehouse\n",
    "\n",
    "SQL Wharehouse are managed by databricks. [Creating a warehouse](/sql/warehouses) is a 1-click step. \n",
    "For the purpose of the hackathon a shared Warehouse has been created already. So no need to create an additional one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55fb3d47-0187-4c34-91ab-087819c27956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating your first Query\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img style=\"float: right; margin-left: 10px\" width=\"600px\" src=\"https://raw.githubusercontent.com/QuentinAmbard/databricks-demo/main/retail/resources/images/lakehouse-retail/lakehouse-retail-dbsql-query.png\" />\n",
    "\n",
    "Our users can now start running SQL queries using the SQL editor and add new visualizations.\n",
    "\n",
    "By leveraging auto-completion and the schema browser, we can start running adhoc queries on top of our data.\n",
    "\n",
    "While this is ideal for Data Analyst to start analysing our fraud dataset, other personas can also leverage DBSQL to track our data ingestion pipeline, the data quality, model behavior etc.\n",
    "\n",
    "Open the [Queries menu](/sql/queries) to start writting your first analysis. Use the SQL code below for a quick start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24a2e1ed-ac1e-4d32-97b1-9ae75e2f1448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **_Task 6 Start_**\n",
    "\n",
    "6.1 Open the **SQL Editor**, create a new SQL Statement, rename the new query tab with YourName_TestQuery -> \"MaxMustermann_TestQuery\"\n",
    " and write a simple SQL query to retrieve all data from YourCatalog_YourSchema.gold_transactions with a LIMIT 1000. \n",
    "Save the Statement as a query (top right save option). \n",
    "Find the saved query in the “Queries” Menu section, open it and look into the share and scheduling options\n",
    "\n",
    "\n",
    "6.2 Write another SQL Statement that retrieves the _id_, _country_ and _isfraud_ from YourCatalog_YourSchema.gold_transactions. \n",
    "Execute the query and add a graph for x column = country, y = sum of isFraud in your SQL Editor view (small plus sign above the query output)\n",
    "\n",
    "6.3 Select the small drop down at the visualization, and create a new dashboard based on this graph. Name it FirstNameLastName_AllianzHackathonDashboard.\n",
    "\n",
    "6.4 Before moving on with the Dashboard, open your \"03-BI-Datawarehousing-fraud\" notebook again. \n",
    "Execute the SQL code Select * from YourCatalog.YourSchema.gold_transactions **LIMIT 100**; \n",
    "Notice that you can do the same things in a Notebook. Why do you think SQLQuerys and specific compute exist? \n",
    "\n",
    "6.5 In this notebook after executing the Select * from YourCatalog.YourSchema.gold_transactions **LIMIT 100** you could create a visualization via the small plus sign too. Instead visualization choose the \"Data Profile\" option.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6140257-9853-4d16-a94c-22bf701fd156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  dbutils.data.summarize(spark.sql(r\"\"\"Select * from psprenger_staging_catalog_internal.allianz_lakehouse_fsi_fraud.gold_transactions LIMIT 100 \"\"\"))\nelse:\n  print(\"This DBR version does not support data profiles.\")\n",
       "commandTitle": "Data Profile 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1750151578701,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "c527b428-7324-44d8-bef9-43333a54446d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.48828125,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1750151562904,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1750151562446,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "/*Select * from psprenger_staging_catalog_internal.allianz_lakehouse_fsi_fraud.gold_transactions LIMIT 100;*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd6cc120-2c26-47f7-a3fc-55168318b5d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Task 6 End**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d895de3f-8dc6-4ba9-b41f-22e8ce5b0457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **_Task 7 Start_**\n",
    "\n",
    "7.1 In task 6 you created a dashboard. If you have it still open, navigate to the tab. \n",
    "Otherwise you can find it under Dashboard, remember you named it FirstNameLastName_AllianzHackathonDashboard.\n",
    "\n",
    "7.2 In the dashboard switch from the canvas to the data tab view, you can see the SQL statement you added before as a datasource. Give it a meaningful name. \n",
    "You can also add datasources via the catalog explorer view. Choose \"Add data source\", choose your catalog, schema and the banking_customers table. Run the statement and switch back to the canvas view.\n",
    "\n",
    "7.3 In the canvas view create a new visualization via the blue navigation menu. Use the AI assitant feature ask for \"Fraud Transactions by Country\". \n",
    "See how the assistant does the same SQL visualisations you beforehand spend minutes on in some seconds & sorts it in descending order. \n",
    "\n",
    "7.4 In the canvas view publish the dashboard. Choose to embed credentials or not embed credentials based on who you think should be able to access such a dashboard. Switch to the publish view (top, middle above your dashboard) to view the published version.\n",
    "\n",
    "\n",
    "# **_Task 7 End_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "520bca2b-b454-46cc-a864-7ef78f193752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating our Fraud Analysis Dashboard\n",
    "\n",
    "<img style=\"float: right; margin-left: 10px\" width=\"600px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/lakehouse-fsi-fraud-dashboard.png\" />\n",
    "\n",
    "The next step is now to assemble our queries and their visualization in a comprehensive SQL dashboard that our business will be able to track.\n",
    "\n",
    "The Dashboard has been loaded for you. Open the <a dbdemos-dashboard-id=\"fraud-detection\" href='/sql/dashboardsv3/01f041519cec119bbf35ae5be0f58c60' target=\"_blank\">DBSQL FSI Fraud Dashboard</a> to start reviewing our existing Fraud pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de2d3f69-51bb-4d58-9b39-25a425de0cbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Using Third party BI tools\n",
    "\n",
    "<iframe style=\"float: right; margin-left: 10px\" width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/EcKqQV0rCnQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "SQL warehouse can also be used with an external BI tool such as Tableau or PowerBI.\n",
    "\n",
    "This will allow you to run direct queries on top of your table, with a unified security model and Unity Catalog (ex: through SSO). Now analysts can use their favorite tools to discover new business insights on the most complete and freshest data.\n",
    "\n",
    "To start using your Warehouse with third party BI tool, click on \"Partner Connect\" on the bottom left and chose your provider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d242060d-34d7-4c27-9c56-8dcd19dd37d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Going further with DBSQL & Databricks Warehouse\n",
    "\n",
    "Databricks SQL offers much more and provides a full warehouse capabilities\n",
    "\n",
    "<img style=\"float: right\" width=\"400px\" src=\"https://raw.githubusercontent.com/QuentinAmbard/databricks-demo/main/retail/resources/images/lakehouse-retail/lakehouse-retail-dbsql-pk-fk.png\" />\n",
    "\n",
    "### Data modeling\n",
    "\n",
    "Comprehensive data modeling. Save your data based on your requirements: Data vault, Star schema, Inmon...\n",
    "\n",
    "Databricks let you create your PK/FK, identity columns (auto-increment): `dbdemos.install('identity-pk-fk')`\n",
    "\n",
    "### Data ingestion made easy with DBSQL & DBT\n",
    "\n",
    "Turnkey capabilities allow analysts and analytic engineers to easily ingest data from anything like cloud storage to enterprise applications such as Salesforce, Google Analytics, or Marketo using Fivetran. It’s just one click away. \n",
    "\n",
    "Then, simply manage dependencies and transform data in-place with built-in ETL capabilities on the Lakehouse (Delta Live Table), or using your favorite tools like dbt on Databricks SQL for best-in-class performance.\n",
    "\n",
    "### Query federation\n",
    "\n",
    "Need to access cross-system data? Databricks SQL query federation let you define datasources outside of databricks (ex: PostgreSQL)\n",
    "\n",
    "### Materialized view\n",
    "\n",
    "Avoid expensive queries and materialize your tables. The engine will recompute only what's required when your data get updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d072d3ff-e4d8-4d55-ba26-1e91a726e2be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Taking our analysis one step further: Detecting Fraud\n",
    "\n",
    "Being able to run analysis on our past data already gives us a lot of insight. We can better understand our fraud pattern and quantify their impact.\n",
    "\n",
    "However, knowing that we had past fraud isn't enough. We now need to take it to the next level and build a predictive model to flag financial transaction as fraud in real time, improving our revenue and reducing risl.\n",
    "\n",
    "Let's see how this can be done with [Databricks Machine Learning notebook]($../04-Data-Science-ML/04.1-AutoML-FSI-fraud) |  [Go back to the introduction]($../00-FSI-fraud-detection-introduction-lakehouse)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03-BI-Datawarehousing-fraud",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
