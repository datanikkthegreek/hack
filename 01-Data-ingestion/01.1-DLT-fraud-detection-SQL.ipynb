{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c76ead3-2554-4a6d-9b35-2b46463b01c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data engineering with Databricks - Realtime data ingestion for Financial transactions\n",
    "\n",
    "Building realtime system consuming messages from live system is required to build reactive data application. \n",
    "\n",
    "Near real-time is key to detect new fraud pattern and build a proactive system, offering better protection for your customers.\n",
    "\n",
    "Ingesting, transforming and cleaning data to create clean SQL tables for our downstream user (Data Analysts and Data Scientists) is complex.\n",
    "\n",
    "<link href=\"https://fonts.googleapis.com/css?family=DM Sans\" rel=\"stylesheet\"/>\n",
    "<div style=\"width:300px; text-align: center; float: right; margin: 30px 60px 10px 10px;  font-family: 'DM Sans'\">\n",
    "  <div style=\"height: 300px; width: 300px;  display: table-cell; vertical-align: middle; border-radius: 50%; border: 25px solid #fcba33ff;\">\n",
    "    <div style=\"font-size: 70px;  color: #70c4ab; font-weight: bold\">\n",
    "      73%\n",
    "    </div>\n",
    "    <div style=\"color: #1b5162;padding: 0px 30px 0px 30px;\">of enterprise data goes unused for analytics and decision making</div>\n",
    "  </div>\n",
    "  <div style=\"color: #bfbfbf; padding-top: 5px\">Source: Forrester</div>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "## <img src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/images/de.png\" style=\"float:left; margin: -35px 0px 0px 0px\" width=\"80px\"> John, as Data engineer, spends immense timeâ€¦.\n",
    "\n",
    "\n",
    "* Hand-coding data ingestion & transformations and dealing with technical challenges:<br>\n",
    "  *Supporting streaming and batch, handling concurrent operations, small files issues, GDPR requirements, complex DAG dependencies...*<br><br>\n",
    "* Building custom frameworks to enforce quality and tests<br><br>\n",
    "* Building and maintaining scalable infrastructure, with observability and monitoring<br><br>\n",
    "* Managing incompatible governance models from different systems\n",
    "<br style=\"clear: both\">\n",
    "\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=984752964297111&notebook=%2F01-Data-ingestion%2F01.1-DLT-fraud-detection-SQL&demo_name=lakehouse-fsi-fraud&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-fraud%2F01-Data-ingestion%2F01.1-DLT-fraud-detection-SQL&version=1&user_hash=086247655aad7f847fc5af0bced92d31b6454844129a39a1b73eef221886867a\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7940f84-b790-486e-8826-8d128c68b63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Demo: build a banking database and detect fraud on transaction in real-time (ms)\n",
    "\n",
    "In this demo, we'll step in the shoes of a retail banking company processing transaction.\n",
    "\n",
    "The business has determined that we should improve our transaction fraud system and offer a better protection to our customers (retail and institutions using our payment systems). We're asked to:\n",
    "\n",
    "* Analyse and explain current transactions: quantify fraud, understand pattern and usage\n",
    "* Build a proactive system to detect fraud and serve prediction in real-time (ms latencies)\n",
    "\n",
    "\n",
    "### What we'll build\n",
    "\n",
    "To do so, we'll build an end-to-end solution with the Lakehouse. To be able to properly analyse and detect fraud, we'll mainly focus on transactional data, received by our banking system.\n",
    "\n",
    "At a very high level, this is the flow we'll implement:\n",
    "\n",
    "<img width=\"1000px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/lakehouse-fsi-fraud-overview-1.png\" />\n",
    "\n",
    "1. Ingest and create our banking database, with tables easy to query in SQL\n",
    "2. Secure data and grant read access to the Data Analyst and Data Science teams.\n",
    "3. Run BI queries to analyse existing fraud\n",
    "4. Build an ML model to detect fraud and deploy this model for real-time inference\n",
    "\n",
    "As a result, we'll have all the information required to trigger alerts and ask our customer for stronger authentication if we believe there is a high fraud risk.\n",
    "\n",
    "**A note on Fraud detection in real application** <br/>\n",
    "*This demo is a simple example to showcase the Lakehouse benefits. We'll keep the data model and ML simple for the sake of the demo. Real-world application would need more data sources and also deal with imbalanced class and more advanced models. If you are interested in a more advanced discussion, reach out to your Databricks team!*\n",
    "\n",
    "Let's see how this data can be used within the Lakehouse to analyse and reduce fraud!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "352cb472-a4a8-4a79-94c2-c4430e4899d9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "\n",
    "## Building a Delta Live Table pipeline to analyze and reduce fraud detection in real-time\n",
    "\n",
    "In this example, we'll implement a end 2 end DLT pipeline consuming our banking transactions information. We'll use the medaillon architecture but we could build star schema, data vault or any other modelisation.\n",
    "\n",
    "We'll incrementally load new data with the autoloader and enrich this information.\n",
    "\n",
    "This information will then be used  to:\n",
    "\n",
    "* Build our DBSQL dashboard to track transactions and fraud impact.\n",
    "* Train & deploy a model to detect potential fraud in real-time.\n",
    "\n",
    "Let's implement the following flow: \n",
    " \n",
    "<img width=\"1200px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/fsi-fraud-dlt-full.png\"/>\n",
    "\n",
    "\n",
    "*Note that we're including the ML model our [Data Scientist built]($../04-Data-Science-ML/04.1-automl-fraud-detection) using Databricks AutoML to predict fraud. We'll cover that in the next section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e7fdaa2-3f86-4815-95b5-d805eb29b5a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Your DLT Pipeline has been installed and started for you! Open the <a dbdemos-pipeline-id=\"dlt-fsi-fraud\" href=\"#joblist/pipelines/9c690e9c-75bf-4653-a170-a21bfcfca6bb\" target=\"_blank\">Fraud detection Delta Live Table pipeline</a> to see it in action.<br/>\n",
    "*(Note: The pipeline will automatically start once the initialization job is completed, this might take a few minutes... Check installation logs for more details)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd0c4ca8-3ac2-4ad8-b1e1-c570e0b9e7fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1/ Loading our data using Databricks Autoloader (cloud_files)\n",
    "\n",
    "<img  style=\"float:right; margin-left: 10px\" width=\"600px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/fsi-fraud-dlt-1.png\"/>\n",
    "  \n",
    "Autoloader allow us to efficiently ingest millions of files from a cloud storage, and support efficient schema inference and evolution at scale.\n",
    "\n",
    "For more details on autoloader, run `dbdemos.install('auto-loader')`\n",
    "\n",
    "Let's use it to our pipeline and ingest the raw JSON & CSV data being delivered in our blob storage `/dbdemos/fsi/fraud-detection/...`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a8487a9-5fcd-4162-aad9-75e60d1c8bc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "###Task 0: \n",
    "###Complete Notebook setup. \n",
    "In the following statements you have to replace the \"YOUR_CATALOG_HERE\" with the catalog you defined in your setup. \n",
    "That should be \"firstnamelastname_allianz\"\n",
    "\n",
    "\n",
    "**After** you have **completed** task 1 and task 2 and run the notebook, you can create a pipeline via the blue \"Create Pipeline\" button below. \n",
    "In the pipeline config you will select in section destination Unity Catalog, your catalog and your schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aec0653-fd0e-448e-9855-43f20ddd6a0d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest transactions"
    }
   },
   "outputs": [],
   "source": [
    "CREATE STREAMING LIVE TABLE bronze_transactions \n",
    "  COMMENT \"Historical banking transaction to be trained on fraud detection\"\n",
    "AS \n",
    "  SELECT * FROM cloud_files(\"/Volumes/YOUR_CATALOG_HERE/allianz_lakehouse_fsi_fraud/fraud_raw_data/transactions\", \"json\", map(\"cloudFiles.maxFilesPerTrigger\", \"1\", \"cloudFiles.inferColumnTypes\", \"true\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2dec9ea-f441-4744-9983-d198d28b40de",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Customers"
    }
   },
   "outputs": [],
   "source": [
    "CREATE STREAMING LIVE TABLE banking_customers (\n",
    "  CONSTRAINT correct_schema EXPECT (_rescued_data IS NULL)\n",
    ")\n",
    "COMMENT \"Customer data coming from csv files ingested in incremental with Auto Loader to support schema inference and evolution\"\n",
    "AS \n",
    "  SELECT * FROM cloud_files(\"/Volumes/YOUR_CATALOG_HERE/allianz_lakehouse_fsi_fraud/fraud_raw_data/customers\", \"csv\", map(\"cloudFiles.inferColumnTypes\", \"true\", \"multiLine\", \"true\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062681ef-b1af-4b01-b6f5-3746ff44697d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reference table"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "CREATE STREAMING LIVE TABLE country_coordinates\n",
    "AS \n",
    "  SELECT * FROM cloud_files(\"/Volumes/YOUR_CATALOG_HERE/allianz_lakehouse_fsi_fraud/fraud_raw_data/country_code\", \"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14025175-10fc-48f1-a01e-f745ef8e2f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **_TASK 1 Start_**\n",
    "\n",
    "Ingest the csv files that is located at the volume path: /Volumes/\"yourcatalog\"/\"yourschema\"/fraud_raw_data/fraud_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c0df33e-c421-429e-bc53-eab483d29abf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fraud report (labels for ML training)"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "/* Write your code below*/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07df2430-c103-4099-a9aa-755727a9e73b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **_TASK 1 END_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "292ec55b-f319-408f-b858-cf3bb0c745a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2/ Enforce quality and materialize our tables for Data Analysts\n",
    "\n",
    "<img style=\"float:right; margin-left: 10px\" width=\"600px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/fsi-fraud-dlt-2.png\"/>\n",
    "\n",
    "\n",
    "The next layer often call silver is consuming **incremental** data from the bronze one, and cleaning up some information:\n",
    "\n",
    "* Clean up the codes of the countries of origin and destination (removing the \"--\")\n",
    "* Calculate the difference between the Originating and Destination Balances.\n",
    "\n",
    "We're also adding an [expectation](https://docs.databricks.com/workflows/delta-live-tables/delta-live-tables-expectations.html) on different field to enforce and track our Data Quality. This will ensure that our dashboard are relevant and easily spot potential errors due to data anomaly.\n",
    "\n",
    "For more advanced DLT capabilities run `dbdemos.install('dlt-loans')` or `dbdemos.install('dlt-cdc')` for CDC/SCDT2 example.\n",
    "\n",
    "These tables are clean and ready to be used by the BI team!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ff6145a-bc1e-4541-b900-a2323f584ab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **_# Task 2 Start_**\n",
    "\n",
    "\n",
    "You need to ensure good data quality. \n",
    "Please implement in the following code snippe: \n",
    "1. correct_data should not be null **and** \n",
    "2. correct_customer_id should not be null\n",
    "\n",
    "Leverage the code snippet below (remove the comment tags /* */ and add the constraints\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a24dcc09-c30a-4a1c-8438-5bf37ae1adc3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Silver"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "/* uncomment an replace missing parts\n",
    "CREATE STREAMING LIVE TABLE silver_transactions (\n",
    "  CONSTRAINT YOURCODE,\n",
    "  CONSTRAINT YOUR CODE\n",
    ")\n",
    "AS \n",
    "  SELECT * EXCEPT(countryOrig, countryDest, t._rescued_data, f._rescued_data), \n",
    "          regexp_replace(countryOrig, \"\\-\\-\", \"\") as countryOrig, \n",
    "          regexp_replace(countryDest, \"\\-\\-\", \"\") as countryDest, \n",
    "          newBalanceOrig - oldBalanceOrig as diffOrig, \n",
    "          newBalanceDest - oldBalanceDest as diffDest\n",
    "FROM STREAM(live.bronze_transactions) t\n",
    "  LEFT JOIN live.fraud_reports f using(id)\n",
    "\n",
    "*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bd71ad5-653d-4411-968d-ca1bf607c946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3/ Aggregate and join data to create our ML features\n",
    "\n",
    "<img style=\"float:right; margin-left: 10px\" width=\"600px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/fsi-fraud-dlt-3.png\"/>\n",
    "\n",
    "We're now ready to create the features required for Fraud detection.\n",
    "\n",
    "We need to enrich our transaction dataset with extra information our model will use to help detecting churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3edb7fdb-5d1a-4085-903b-d89fef1fed8d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Gold, ready for Data Scientists to consume"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "CREATE LIVE TABLE gold_transactions (\n",
    "  CONSTRAINT amount_decent EXPECT (amount > 10)\n",
    ")\n",
    "AS \n",
    "  SELECT t.* EXCEPT(countryOrig, countryDest, is_fraud), c.* EXCEPT(id, _rescued_data),\n",
    "          boolean(coalesce(is_fraud, 0)) as is_fraud,\n",
    "          o.alpha3_code as countryOrig, o.country as countryOrig_name, o.long_avg as countryLongOrig_long, o.lat_avg as countryLatOrig_lat,\n",
    "          d.alpha3_code as countryDest, d.country as countryDest_name, d.long_avg as countryLongDest_long, d.lat_avg as countryLatDest_lat\n",
    "FROM live.silver_transactions t\n",
    "  INNER JOIN live.country_coordinates o ON t.countryOrig=o.alpha3_code \n",
    "  INNER JOIN live.country_coordinates d ON t.countryDest=d.alpha3_code \n",
    "  INNER JOIN live.banking_customers c ON c.id=t.customer_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "975bd740-785b-4b66-b602-d1ca3cbd3ef7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Our pipeline is now ready!\n",
    "\n",
    "As you can see, building Data Pipeline with databricks let you focus on your business implementation while the engine solves all hard data engineering work for you.\n",
    "\n",
    "The table is now ready for our Data Scientist to train a model detecting fraud risk.\n",
    "\n",
    "Open the <a dbdemos-pipeline-id=\"dlt-fsi-fraud\" href=\"#joblist/pipelines/9c690e9c-75bf-4653-a170-a21bfcfca6bb\" target=\"_blank\">Fraud detection Delta Live Table pipeline</a> and click on start to visualize your lineage and consume the new data incrementally!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8afca340-809a-4ca3-8b03-a3f4b634791a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Next: secure and share data with Unity Catalog\n",
    "\n",
    "Now that these tables are available in our Lakehouse, let's review how we can share them with the Data Scientists and Data Analysts teams.\n",
    "\n",
    "Jump to the [Governance with Unity Catalog notebook]($../00-churn-introduction-lakehouse) or [Go back to the introduction]($../00-churn-introduction-lakehouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5958e2f1-1174-482a-a6b2-63c8014f26a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "\n",
    "### Source Data\n",
    "\n",
    "This dataset is built with PaySim, an open source banking transactions simulator.\n",
    "\n",
    "[PaySim](https://github.com/EdgarLopezPhD/PaySim) simulates mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01.1-DLT-fraud-detection-SQL",
   "widgets": {
    "catalog": {
     "currentValue": "",
     "nuid": "fb7b7da4-6852-473d-aaef-e34baafea238",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "psprenger_allianz",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "psprenger_allianz",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "",
     "nuid": "1c6c8757-c312-4c96-a882-5753e61615de",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "allianz_lakehouse_fsi_fraud",
      "label": null,
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "allianz_lakehouse_fsi_fraud",
      "label": null,
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
