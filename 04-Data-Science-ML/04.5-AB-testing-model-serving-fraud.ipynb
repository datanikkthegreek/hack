{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4edce4c9-9151-4622-96d8-e8d8317f728f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# New Model deployement with A/B testing \n",
    "\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/model-serving-ab-testing.png\" width=\"800px\" />\n",
    "\n",
    "Our new model is now saved in our Registry.\n",
    "\n",
    "Our next step is now to deploy it while ensuring that it's behaving as expected. We want to be able to deploy the new version in the REST API:\n",
    "\n",
    "* Without making any production outage\n",
    "* Slowly routing requests to the new model\n",
    "* Supporting auto-scaling & potential bursts\n",
    "* Performing some A/B testing ensuring the new model is providing better outcomes\n",
    "* Monitorig our model outcome and technical metrics (CPU/load etc)\n",
    "\n",
    "Databricks makes this process super simple with Serverless Model Serving endpoint.\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=984752964297111&notebook=%2F04-Data-Science-ML%2F04.5-AB-testing-model-serving-fraud&demo_name=lakehouse-fsi-fraud&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-fraud%2F04-Data-Science-ML%2F04.5-AB-testing-model-serving-fraud&version=1&user_hash=086247655aad7f847fc5af0bced92d31b6454844129a39a1b73eef221886867a\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbd448c3-38c5-4064-b92b-21c4693f38c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.36.0 mlflow==2.19.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "202ababd-53c1-4174-b5d1-cea8a9a4ecea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42480e69-5bb0-419b-be6b-5be87441688b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Routing our Model Serving endpoint to multiple models\n",
    "<img style=\"float: right; margin-left: 10px\" width=\"700px\" src=\"https://cms.databricks.com/sites/default/files/inline-images/db-498-blog-imgs-1.png\" />\n",
    "\n",
    "Databricks Model Serving endpoints allow you to serve different models and dynamically redirect a subset of the traffic to a given model.\n",
    "\n",
    "Open your <a href=\"#mlflow/endpoints/dbdemos_fsi_fraud\" target=\"_blank\"> Model Serving Endpoint</a>, edit the configuration and add our second model.\n",
    "\n",
    "Select the traffic ratio you want to send to the new model (20%), save and Databricks will handle the rest for you. \n",
    "\n",
    "Your endpoint will automatically bundle the new model, and start routing a subset of your queries to this model.\n",
    "\n",
    "Let's see how this can be done using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b7a43ff-8d2e-4ca9-b455-0cbe927748fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk.service.serving import ServedEntityInput, EndpointCoreConfigInput, AutoCaptureConfigInput, TrafficConfig, Route\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from mlflow import MlflowClient\n",
    "from datetime import timedelta\n",
    "\n",
    "model_name = f\"{catalog}.{db}.dbdemos_fsi_fraud\"\n",
    "serving_endpoint_name = \"dbdemos_fsi_fraud_endpoint\"\n",
    "\n",
    "w = WorkspaceClient()\n",
    "mlflow_client = MlflowClient(registry_uri=\"databricks-uc\")\n",
    "served_entities=[\n",
    "        ServedEntityInput(\n",
    "            name=\"prod_model\",\n",
    "            entity_name=model_name,\n",
    "            entity_version=mlflow_client.get_model_version_by_alias(model_name, \"prod\").version,\n",
    "            scale_to_zero_enabled=True,\n",
    "            workload_size=\"Small\"\n",
    "        ),\n",
    "        ServedEntityInput(\n",
    "            name=\"candidate_model\",\n",
    "            entity_name=model_name,\n",
    "            entity_version=mlflow_client.get_model_version_by_alias(model_name, \"candidate\").version,\n",
    "            scale_to_zero_enabled=True,\n",
    "            workload_size=\"Small\"\n",
    "        )\n",
    "    ]\n",
    "traffic_config=TrafficConfig(routes=[\n",
    "        Route(\n",
    "            served_model_name=\"prod_model\",\n",
    "            traffic_percentage=90\n",
    "        ),\n",
    "        Route(\n",
    "            served_model_name=\"candidate_model\",\n",
    "            traffic_percentage=10\n",
    "        )\n",
    "    ])\n",
    "\n",
    "print('Updating the endpoint, this will take a few sec, please wait...')\n",
    "w.serving_endpoints.update_config_and_wait(name=serving_endpoint_name, served_entities=served_entities, traffic_config=traffic_config, timeout=timedelta(minutes=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5678cf1-ee3b-4fba-850e-7e831a2e608c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Our new model is now serving 10% of our requests\n",
    "\n",
    "Open your <a href=\"#mlflow/endpoints/dbdemos_fsi_fraud_endpoint\" target=\"_blank\"> Model Serving Endpoint</a> to view the changes and track the 2 models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10db6baa-910a-48bb-9287-c817d6eaa2b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n",
    "from mlflow.models.model import Model\n",
    "\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "p = ModelsArtifactRepository(f\"models:/{model_name}@prod\").download_artifacts(\"\")\n",
    "dataset =  {\"dataframe_split\": Model.load(p).load_input_example(p).to_dict(orient='split')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5744456c-02f4-4a4b-b4af-4486aa0484c1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Trying our new Model Serving setup"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import deployments\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "#Let's do multiple call to track the results in the model endpoint inference table\n",
    "for i in range(10):\n",
    "    predictions = client.predict(endpoint=serving_endpoint_name, inputs=dataset)\n",
    "    print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71ac8786-1e01-48e4-bc1d-a3c3ce6e4671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Model monitoring and A/B testing analysis\n",
    "\n",
    "Because the Model Serving runs within our Lakehouse, Databricks will automatically save and track all our Model Endpoint results as a Delta Table.\n",
    "\n",
    "We can then easily plug a feedback loop to start analysing the revenue in $ each model is offering. \n",
    "\n",
    "All these metrics, including A/B testing validation (p-values etc) can then be pluged into a Model Monitoring Dashboard and alerts can be sent for errors, potentially triggering new model retraining or programatically updating the Endpoint routes to fallback to another model.\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/model-serving-monitoring.png\" width=\"1200px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29e401d4-f360-472e-80a5-417ad38b91bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion: the power of the Lakehouse\n",
    "\n",
    "In this demo, we've seen an end 2 end flow with the Lakehouse:\n",
    "\n",
    "- Data ingestion made simple with Delta Live Table\n",
    "- Leveraging Databricks warehouse to Analyze existing Fraud\n",
    "- Model Training with AutoML for citizen Data Scientist\n",
    "- Ability to tune our model for better results, improving our revenue\n",
    "- Ultimately, the ability to Deploy and track our models in real time, made possible with the full lakehouse capabilities.\n",
    "\n",
    "[Go back to the introduction]($../00-FSI-fraud-detection-introduction-lakehouse) or discover how to use Databricks Workflow to orchestrate this tasks: [05-Workflow-orchestration-fsi-fraud]($../05-Workflow-orchestration/05-Workflow-orchestration-fsi-fraud)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04.5-AB-testing-model-serving-fraud",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
