{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54f07467-dfaf-49f2-a8f9-e901b40208f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploying AutoML model for realtime serving\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/fsi-fraud-real-time-serving.png\" width=\"700px\" />\n",
    "\n",
    "Let's deploy our model behind a scalable API to rate a Fraud likelihood in ms and reduce fraud in real-time.\n",
    "\n",
    "## Databricks Model Serving\n",
    "\n",
    "Now that our model has been created with Databricks AutoML, we can easily flag it as Production Ready and turn on Databricks Model Serving.\n",
    "\n",
    "We'll be able to send HTTP Requests and get inference in real-time.\n",
    "\n",
    "Databricks Model Serving is a fully serverless:\n",
    "\n",
    "* One-click deployment. Databricks will handle scalability, providing blazing fast inferences and startup time.\n",
    "* Scale down to zero as an option for best TCO (will shut down if the endpoint isn't used)\n",
    "* Built-in support for multiple models & version deployed\n",
    "* A/B Testing and easy upgrade, routing traffic between each versions while measuring impact\n",
    "* Built-in metrics & monitoring\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=984752964297111&notebook=%2F04-Data-Science-ML%2F04.3-Model-serving-realtime-inference-fraud&demo_name=lakehouse-fsi-fraud&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-fraud%2F04-Data-Science-ML%2F04.3-Model-serving-realtime-inference-fraud&version=1&user_hash=086247655aad7f847fc5af0bced92d31b6454844129a39a1b73eef221886867a\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3fab912-a697-4942-b189-8075da81d06c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.36.0 mlflow==2.19.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e2159cb-fd19-4f96-8c8b-2470545a04e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81f2318f-6958-46e8-93a1-01c0901729d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating our Model Serving endpoint\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/fsi-fraud-model-serving-ui.png\" style=\"float: right; margin-left: 10px\" width=\"400px\"/>\n",
    "\n",
    "Let's start our Serverless Databricks Model Serving Endpoint. \n",
    "\n",
    "To do it with the UI, make sure you are under the \"Machine Learning\" Persona (top left) and select Open your <a href=\"#mlflow/endpoints\" target=\"_blank\">\"Model Serving\"</a>. \n",
    "\n",
    "Then select the model we created: `dbdemos_fsi_fraud` and the latest version available.\n",
    "\n",
    "In addition, we'll allow the endpoint to scale down to zero (the endpoint will shut down after a few minutes without requests). Because it's serverless, it'll be able to restart within a few seconds.\n",
    "\n",
    "*Note that the first startup time will take extra second as the model container image is being built. It's then saved to ensure faster startup time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8bc3e88-52ed-47f3-a2d4-6efe8ac629c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "model_name = \"dbdemos_fsi_fraud\"\n",
    "mlflow.set_registry_uri('databricks-uc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f1cb17c-36fd-48cb-be1c-0cfd13b573b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Starting the model inference REST endpoint using Databricks API"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import ServedEntityInput, EndpointCoreConfigInput, AutoCaptureConfigInput\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "model_name = f\"{catalog}.{db}.dbdemos_fsi_fraud\"\n",
    "serving_endpoint_name = \"dbdemos_fsi_fraud_endpoint\"\n",
    "w = WorkspaceClient()\n",
    "\n",
    "mlflow_client = MlflowClient(registry_uri=\"databricks-uc\")\n",
    "endpoint_config = EndpointCoreConfigInput(\n",
    "    name=serving_endpoint_name,\n",
    "    served_entities=[\n",
    "        ServedEntityInput(\n",
    "            entity_name=model_name,\n",
    "            entity_version=mlflow_client.get_model_version_by_alias(model_name, \"prod\").version,\n",
    "            scale_to_zero_enabled=True,\n",
    "            workload_size=\"Small\"\n",
    "        )\n",
    "    ],\n",
    "    auto_capture_config = AutoCaptureConfigInput(catalog_name=catalog, schema_name=db, enabled=True, table_name_prefix=\"fraud_ep_inference_table\" )\n",
    ")\n",
    "\n",
    "force_update = False #Set this to True to release a newer version (the demo won't update the endpoint to a newer model version by default)\n",
    "try:\n",
    "  existing_endpoint = w.serving_endpoints.get(serving_endpoint_name)\n",
    "  print(f\"endpoint {serving_endpoint_name} already exist...\")\n",
    "  if force_update:\n",
    "    w.serving_endpoints.update_config_and_wait(served_entities=endpoint_config.served_entities, name=serving_endpoint_name)\n",
    "except:\n",
    "    print(f\"Creating the endpoint {serving_endpoint_name}, this will take a few minutes to package and deploy the endpoint...\")\n",
    "    spark.sql('drop table if exists fraud_ep_inference_table_payload')\n",
    "    w.serving_endpoints.create_and_wait(name=serving_endpoint_name, config=endpoint_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "120082dd-644d-4c21-bc41-7cd4ee33190a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Running HTTP REST inferences in realtime !"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n",
    "from mlflow.models.model import Model\n",
    "\n",
    "p = ModelsArtifactRepository(f\"models:/{model_name}@prod\").download_artifacts(\"\") \n",
    "dataset =  {\"dataframe_split\": Model.load(p).load_input_example(p).to_dict(orient='split')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ff7d513-80b8-42c9-9f48-b87943aa0530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import deployments\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "predictions = client.predict(endpoint=serving_endpoint_name, inputs=dataset)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3460a57e-1740-4171-9633-8061b157ae3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## We now have our first model version available in production for real time inference!\n",
    "\n",
    "Open your [model endpoint](#mlflow/endpoints/dbdemos_fsi_fraud).\n",
    "\n",
    "We can now start using the endpoint API to send queries and start detecting potential fraud in real-time.\n",
    "\n",
    "We would typically add an extra security challenge if the model thinks this is a potential fraud. \n",
    "\n",
    "This would allow to make simple transaction flow, without customer friction when the model is confident it's not a fraud, and add more security layers when we flag it as a potential fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee95fd50-f162-4a65-b435-f9b54721009c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next: Release a new model version and deploy it without interrupting our service\n",
    "\n",
    "After a review of the notebook generated by Databricks AutoML, our Data Scientists realized that we could better detect fraud by retraining a model better at handling imbalanced dataset.\n",
    "\n",
    "Open the next notebook [04.4-Upgrade-to-imbalance-and-xgboost-model-fraud]($./04.4-Upgrade-to-imbalance-and-xgboost-model-fraud) to train a new model and add it to our registry."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04.3-Model-serving-realtime-inference-fraud",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
