{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ffe944b-d291-4282-8670-7b67867bb5d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Data Science with Databricks\n",
    "\n",
    "## ML is key to disruption & risk reduction\n",
    "\n",
    "Being able to ingest and query our banking database is a first step, but this isn't enough to thrive in a very competitive market.\n",
    "\n",
    "Banking customers now expect real time personalization and protection. Modern data company achieve this with AI.\n",
    "\n",
    "<style>\n",
    ".right_box{\n",
    "  margin: 30px; box-shadow: 10px -10px #CCC; width:650px;height:300px; background-color: #1b3139ff; box-shadow:  0 0 10px  rgba(0,0,0,0.6);\n",
    "  border-radius:25px;font-size: 35px; float: left; padding: 20px; color: #f9f7f4; }\n",
    ".badge {\n",
    "  clear: left; float: left; height: 30px; width: 30px;  display: table-cell; vertical-align: middle; border-radius: 50%; background: #fcba33ff; text-align: center; color: white; margin-right: 10px}\n",
    ".badge_b { \n",
    "  height: 35px}\n",
    "</style>\n",
    "<link href='https://fonts.googleapis.com/css?family=DM Sans' rel='stylesheet'>\n",
    "<div style=\"font-family: 'DM Sans'\">\n",
    "  <div style=\"width: 500px; color: #1b3139; margin-left: 50px; float: left\">\n",
    "    <div style=\"color: #ff5f46; font-size:80px\">90%</div>\n",
    "    <div style=\"font-size:30px;  margin-top: -20px; line-height: 30px;\">\n",
    "      Enterprise applications will be AI-augmented by 2025 —IDC\n",
    "    </div>\n",
    "    <div style=\"color: #ff5f46; font-size:80px\">$10T+</div>\n",
    "    <div style=\"font-size:30px;  margin-top: -20px; line-height: 30px;\">\n",
    "       Projected business value creation by AI in 2030 —PWC\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "  <div class=\"right_box\">\n",
    "      But—huge challenges getting ML to work at scale!<br/><br/>\n",
    "      Most ML projects still fail before getting to production\n",
    "  </div>\n",
    "  \n",
    "<br style=\"clear: both\">\n",
    "\n",
    "## Machine learning is data + transforms.\n",
    "\n",
    "ML is hard because delivering value to business lines isn't only about building a Model. <br>\n",
    "The ML lifecycle is made of data pipelines: Data-preprocessing, feature engineering, training, inference, monitoring and retraining...<br>\n",
    "Stepping back, all pipelines are data + code.\n",
    "\n",
    "\n",
    "<img style=\"float: right; margin-top: 10px\" width=\"500px\" src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/images/retail/lakehouse-churn/lakehouse-retail-c360-churn-4.png\" />\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/raw/main/images/ds.png\" style=\"float: left;\" width=\"80px\"> \n",
    "<h3 style=\"padding: 10px 0px 0px 5px\">Marc, as a Data Scientist, needs a data + ML platform accelerating all the ML & DS steps:</h3>\n",
    "\n",
    "<div style=\"font-size: 19px; margin-left: 73px; clear: left\">\n",
    "<div class=\"badge_b\"><div class=\"badge\">1</div> Build Data Pipeline supporting real time (with DLT)</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">2</div> Data Exploration</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">3</div> Feature creation</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">4</div> Build & train model</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">5</div> Deploy Model (Batch or serverless realtime)</div>\n",
    "<div class=\"badge_b\"><div class=\"badge\">6</div> Monitoring</div>\n",
    "</div>\n",
    "\n",
    "**Marc needs A Lakehouse**. Let's see how we can deploy a real-time Fraud Detection model in production within the Lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66c116a5-4174-48d3-a214-66be5f7a7e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Fraud Detection - Single click deployment with AutoML\n",
    "\n",
    "Let's see how we can now leverage the Banking data to build a model rating our Fraud risk on each transaction.\n",
    "\n",
    "Our first step as Data Scientist is to analyze and build the features we'll use to train our model.\n",
    "\n",
    "The transaction table enriched with customer data has been saved within our Delta Live Table pipeline. All we have to do is read this information, analyze it and start an Auto-ML run.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/fraud-detection/fsi-fraud-ds.png\" width=\"1000px\">\n",
    "\n",
    "*Note: Make sure you switched to the \"Machine Learning\" persona on the top left menu.*\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=984752964297111&notebook=%2F04-Data-Science-ML%2F04.1-AutoML-FSI-fraud&demo_name=lakehouse-fsi-fraud&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-fraud%2F04-Data-Science-ML%2F04.1-AutoML-FSI-fraud&version=1&user_hash=086247655aad7f847fc5af0bced92d31b6454844129a39a1b73eef221886867a\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7915acd3-2ae4-41b4-af02-272afcdbd399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.36.0 mlflow==2.19.0 databricks-feature-store==0.17.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c392fe03-1dff-40cd-a5ca-348d3a5dce06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ae6c246-88be-456d-9104-9f0b82751026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data exploration and analysis\n",
    "\n",
    "Let's review our dataset and start analyze the data we have to detect fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7fb27a5-4eee-48df-aed5-d47054983c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1- How much fraud are we talking about?\n",
    "Based on the existing rules, while 3% of the transactions are fraudulent, it takes into account of the 9% of the total amount.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da359c25-8a71-4555-88fd-13629419ca6e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Leverage built-in visualizations to explore your dataset"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select \n",
    "  is_fraud,\n",
    "  count(1) as `Transactions`, \n",
    "  sum(amount) as `Total Amount` \n",
    "from gold_transactions\n",
    "group by is_fraud\n",
    "\n",
    "--Visualization Pie chart: Keys: is_fraud, Values: [Transactions, Total Amount]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "041ef598-cc3d-4eda-9113-af37663e389e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As expected, financial fraud is by nature very imbalanced between fraudulant and normal transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2af26ef-cd3f-4f88-93ef-2d565c6f12c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2- What type of transactions are associated with fraud?\n",
    "Reviewing the rules-based model, it appears that most fraudulent transactions are in the category of `Transfer` and `Cash_Out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efc74900-8d2b-423b-8448-65f3e32b5297",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Run analysis using your usual python plot libraries"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('select type, is_fraud, count(1) as count from gold_transactions group by type, is_fraud').toPandas()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "fig.add_trace(go.Pie(labels=df[df['is_fraud']]['type'], values=df[df['is_fraud']]['count'], title=\"Fraud Transactions\", hole=0.6), 1, 1)\n",
    "fig.add_trace(go.Pie(labels=df[~df['is_fraud']]['type'], values=df[~df['is_fraud']]['count'], title=\"Normal Transactions\", hole=0.6) ,1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37ea6832-5a73-47f5-8a75-68cdbe6a295e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Saving our dataset to Feature Store (Optional)\n",
    "\n",
    "<img src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/product_demos/mlops-end2end-flow-feature-store.png\" style=\"float:right\" width=\"500\" />\n",
    "\n",
    "Once our features are ready, we'll save them in Databricks Feature Store. Under the hood, features store are backed by a Delta Lake table.\n",
    "\n",
    "This will allow discoverability and reusability of our feature accross our organization, increasing team efficiency.\n",
    "\n",
    "Feature store will bring traceability and governance in our deployment, knowing which model is dependent of which set of features. It also simplify realtime serving.\n",
    "\n",
    "Make sure you're using the \"Machine Learning\" menu to have access to your feature store using the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75b88c51-3af3-4105-83fe-f2b862b83762",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the final features using pandas API"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to koalas\n",
    "dataset = spark.table('gold_transactions').dropDuplicates(['id']).pandas_api()\n",
    "# Drop columns we don't want to use in our model\n",
    "# Typical DS project would include more transformations / cleanup here\n",
    "dataset = dataset.drop(columns=['address', 'email', 'firstname', 'lastname', 'creation_date', 'last_activity_date', 'customer_id'])\n",
    "\n",
    "# Drop missing values\n",
    "dataset.dropna()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fdf4aad-8d48-4c37-b1f0-09112ef0f297",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save them to our feature store"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "try:\n",
    "  #drop table if exists\n",
    "  fs.drop_table(f'{catalog}.{db}.transactions_features')\n",
    "except:\n",
    "  pass\n",
    "\n",
    "fs.create_table(\n",
    "  name=f'{catalog}.{db}.transactions_features',\n",
    "  primary_keys='id',\n",
    "  schema=dataset.spark.schema(),\n",
    "  description='These features are derived from the gold_transactions table in the lakehouse.  We created dummy variables for the categorical columns, cleaned up their names, and added a boolean flag for whether the transaction is a fraud or not.  No aggregations were performed.')\n",
    "\n",
    "fs.write_table(df=dataset.to_spark(), name=f'{catalog}.{db}.transactions_features', mode='overwrite')\n",
    "features = fs.read_table(f'{catalog}.{db}.transactions_features')\n",
    "display(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46ad4995-2b95-49a2-b9f5-64b387d68f29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Accelerating Fraud detection model creation using MLFlow and Databricks Auto-ML\n",
    "\n",
    "MLflow is an open source project allowing model tracking, packaging and deployment. Everytime your datascientist team work on a model, Databricks will track all the parameter and data used and will save it. This ensure ML traceability and reproductibility, making it easy to know which model was build using which parameters/data.\n",
    "\n",
    "### AutoML: A glass-box solution that empowers data teams without taking away control\n",
    "\n",
    "While Databricks simplify model deployment and governance (MLOps) with MLFlow, bootstraping new ML projects can still be long and inefficient. \n",
    "\n",
    "Instead of creating the same boilerplate for each new project, Databricks Auto-ML can automatically generate state of the art models for Classifications, regression, and forecast.\n",
    "\n",
    "\n",
    "<img width=\"1000\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/auto-ml-full.png\"/>\n",
    "\n",
    "\n",
    "Models can be directly deployed, or instead leverage generated notebooks to boostrap projects with best-practices, saving you weeks of efforts.\n",
    "\n",
    "<br style=\"clear: both\">\n",
    "\n",
    "<img style=\"float: right\" width=\"600\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/retail/resources/images/churn-auto-ml.png\"/>\n",
    "\n",
    "### Using Databricks Auto ML with our Transaction dataset\n",
    "\n",
    "Auto ML is available in the \"Machine Learning\" space. All we have to do is start a new Auto-ML experimentation and select the feature table we just created (`gold_transactions`)\n",
    "\n",
    "Our prediction target is the `is_fraud` column.\n",
    "\n",
    "Click on Start, and Databricks will do the rest.\n",
    "\n",
    "While this is done using the UI, you can also leverage the [python API](https://docs.databricks.com/applications/machine-learning/automl.html#automl-python-api-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c8df47e-c6a7-411c-bd33-0c2b72c9d532",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Starting AutoML run using Databricks API"
    }
   },
   "outputs": [],
   "source": [
    "xp_path = \"/Shared/dbdemos/experiments/lakehouse-fsi-fraud-detection\"\n",
    "xp_name = f\"automl_fraud_{datetime.now().strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "try:\n",
    "    from databricks import automl\n",
    "    automl_run = automl.classify(\n",
    "        experiment_name = xp_name,\n",
    "        experiment_dir = xp_path,\n",
    "        dataset = features.sample(0.02), #drastically reduce the training size to speedup the demo\n",
    "        target_col = \"is_fraud\",\n",
    "        timeout_minutes = 20\n",
    "    )\n",
    "    #Make sure all users can access dbdemos shared experiment\n",
    "    DBDemos.set_experiment_permission(f\"{xp_path}/{xp_name}\")\n",
    "except Exception as e:\n",
    "    if \"cannot import name 'automl'\" in str(e):\n",
    "        # Note: cannot import name 'automl' from 'databricks' likely means you're using serverless. Dbdemos doesn't support autoML serverless API - this will be improved soon.\n",
    "        # Adding a temporary workaround to make sure it works well for now - ignore this for classic run\n",
    "        DBDemos.create_mockup_automl_run(f\"{xp_path}/{xp_name}\", features.sample(0.02).toPandas())\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df403baa-1042-4acd-b121-5914951487cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "AutoML saved our best model in the MLFlow registry. [Open the dbdemos_fsi fraud model](#mlflow/models/dbdemos_fsi_fraud) to explore its artifact and analyze the parameters used, including traceability to the notebook used for its creation.\n",
    "\n",
    "If we're ready, we can move this model into Production stage in a click, or using the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1726ba6-8dee-470a-91a8-41ea1503fdcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next: deploying our model for Real Time fraud detection serving \n",
    "\n",
    "Now that our model has been created with Databricks AutoML, we can start a Model Endpoint to serve low-latencies fraud detection.\n",
    "\n",
    "We'll be able to rate the Fraud likelihood in ms to reduce fraud in real-time.\n",
    "\n",
    "Open the [04.3-Model-serving-realtime-inference-fraud]($./04.3-Model-serving-realtime-inference-fraud) to deploy our model or review the notebook generated by AutoML [04.2-automl-generated-notebook-fraud]($./04.2-automl-generated-notebook-fraud)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "04.1-AutoML-FSI-fraud",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
